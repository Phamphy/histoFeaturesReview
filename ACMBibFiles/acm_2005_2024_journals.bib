@article{10.1109/TCBB.2019.2960019,
author = {Chen, Jiaojiao and Jiao, Jianbo and He, Shengfeng and Han, Guoqiang and Qin, Jing},
title = {Few-Shot Breast Cancer Metastases Classification via Unsupervised Cell Ranking},
year = {2019},
issue_date = {Sept.-Oct. 2021},
publisher = {IEEE Computer Society Press},
address = {Washington, DC, USA},
volume = {18},
number = {5},
issn = {1545-5963},
url = {https://doi.org/10.1109/TCBB.2019.2960019},
doi = {10.1109/TCBB.2019.2960019},
abstract = {Tumor metastases detection is of great importance for the treatment of breast cancer patients. Various CNN (convolutional neural network) based methods get excellent performance in object detection/segmentation. However, the detection of metastases in hematoxylin and eosin (H&amp;E) stained whole-slide images (WSI) is still challenging mainly due to two aspects. (1) The resolution of the image is too large. (2) lacking labeled training data. Whole-slide images generally stored in a multi-resolution structure with multiple downsampled tiles. It is difficult to feed the whole image into memory without compression. Moreover, labeling images for the pathologists are time-consuming and expensive. In this paper, we study the problem of detecting breast cancer metastases in the pathological image on patch level. To address the abovementioned challenges, we propose a few-shot learning method to classify whether an image patch contains tumor cells. Specifically, we propose a patch-level unsupervised cell ranking approach, which only relies on images with limited labels. The main idea of the proposed method is that when cropping a patch A from the WSI and further cropping a sub-patch B from A, the cell number of A is always larger than that of B. Based on this observation, we make use of the unlabeled images to learn the ranking information of cell counting to extract the abstract features. Experimental results show that our method is effective to improve the patch-level classification accuracy, compared to the traditional supervised method. The source code is publicly available at &lt;uri&gt;https://github.com/fewshot-camelyon&lt;/uri&gt;.},
journal = {IEEE/ACM Trans. Comput. Biol. Bioinformatics},
month = {dec},
pages = {1914–1923},
numpages = {10}
}

@article{10.1109/TCBB.2019.2941195,
author = {Xu, Hongming and Park, Sunho and Hwang, Tae Hyun},
title = {Computerized Classification of Prostate Cancer Gleason Scores from Whole Slide Images},
year = {2020},
issue_date = {Nov.-Dec. 2020},
publisher = {IEEE Computer Society Press},
address = {Washington, DC, USA},
volume = {17},
number = {6},
issn = {1545-5963},
url = {https://doi.org/10.1109/TCBB.2019.2941195},
doi = {10.1109/TCBB.2019.2941195},
abstract = {Histological Gleason grading of tumor patterns is one of the most powerful prognostic predictors in prostate cancer. However, manual analysis and grading performed by pathologists are typically subjective and time-consuming. In this paper, we present an automatic technique for Gleason grading of prostate cancer from H&amp;E stained whole slide pathology images using a set of novel completed and statistical local binary pattern (CSLBP) descriptors. First, the technique divides the whole slide image (WSI) into a set of small image tiles, where salient tumor tiles with high nuclei densities are selected for analysis. The CSLBP texture features that encode pixel intensity variations from circularly surrounding neighborhoods are extracted from salient image tiles to characterize different Gleason patterns. Finally, the CSLBP texture features computed from all tiles are integrated and utilized by the multi-class support vector machine (SVM) that assigns patient slides with different Gleason scores such as 6, 7, or &lt;inline-formula&gt;&lt;tex-math notation="LaTeX"&gt;$geq$&lt;/tex-math&gt;&lt;alternatives&gt;&lt;mml:math&gt;&lt;mml:mo&gt;≥&lt;/mml:mo&gt;&lt;/mml:math&gt;&lt;inline-graphic xlink:href="xu-ieq1-2941195.gif"/&gt;&lt;/alternatives&gt;&lt;/inline-formula&gt; 8. Experiments have been performed on 312 different patient cases selected from the cancer genome atlas (TCGA) and have achieved superior performances over state-of-the-art texture descriptors and baseline methods including deep learning models for prostate cancer Gleason grading.},
journal = {IEEE/ACM Trans. Comput. Biol. Bioinformatics},
month = {dec},
pages = {1871–1882},
numpages = {12}
}

@article{10.1145/3429742,
author = {Fu, Yunfei and Yu, Hongchuan and Yeh, Chih-Kuo and Lee, Tong-Yee and Zhang, Jian J.},
title = {Fast Accurate and Automatic Brushstroke Extraction},
year = {2021},
issue_date = {May 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {2},
issn = {1551-6857},
url = {https://doi.org/10.1145/3429742},
doi = {10.1145/3429742},
abstract = {Brushstrokes are viewed as the artist’s “handwriting” in a painting. In many applications such as style learning and transfer, mimicking painting, and painting authentication, it is highly desired to quantitatively and accurately identify brushstroke characteristics from old masters’ pieces using computer programs. However, due to the nature of hundreds or thousands of intermingling brushstrokes in the painting, it still remains challenging. This article proposes an efficient algorithm for brush Stroke extraction based on a Deep neural network, i.e., DStroke. Compared to the state-of-the-art research, the main merit of the proposed DStroke is to automatically and rapidly extract brushstrokes from a painting without manual annotation, while accurately approximating the real brushstrokes with high reliability. Herein, recovering the faithful soft transitions between brushstrokes is often ignored by the other methods. In fact, the details of brushstrokes in a master piece of painting (e.g., shapes, colors, texture, overlaps) are highly desired by artists since they hold promise to enhance and extend the artists’ powers, just like microscopes extend biologists’ powers. To demonstrate the high efficiency of the proposed DStroke, we perform it on a set of real scans of paintings and a set of synthetic paintings, respectively. Experiments show that the proposed DStroke is noticeably faster and more accurate at identifying and extracting brushstrokes, outperforming the other methods.},
journal = {ACM Trans. Multimedia Comput. Commun. Appl.},
month = {may},
articleno = {44},
numpages = {24},
keywords = {Brushstroke extraction, Pix2Pix network, hard and soft segmentation, painting authentication}
}

@article{10.1109/TCBB.2018.2821127,
author = {Nanni, Loris and Brahnam, Sheryl and Ghidoni, Stefano and Lumini, Alessandra},
title = {Bioimage Classification with Handcrafted and Learned Features},
year = {2019},
issue_date = {May 2019},
publisher = {IEEE Computer Society Press},
address = {Washington, DC, USA},
volume = {16},
number = {3},
issn = {1545-5963},
url = {https://doi.org/10.1109/TCBB.2018.2821127},
doi = {10.1109/TCBB.2018.2821127},
abstract = {Bioimage classification is increasingly becoming more important in many biological studies including those that require accurate cell phenotype recognition, subcellular localization, and histopathological classification. In this paper, we present a new General Purpose GenP bioimage classification method that can be applied to a large range of classification problems. The GenP system we propose is an ensemble that combines multiple texture features both handcrafted and learned descriptors for superior and generalizable discriminative power. Our ensemble obtains a boosting of performance by combining local features, dense sampling features, and deep learning features. Each descriptor is used to train a different Support Vector Machine that is then combined by sum rule. We evaluate our method on a diverse set of bioimage classification tasks each represented by a benchmark database, including some of those available in the IICBU 2008 database. Each bioimage classification task represents a typical subcellular, cellular, and tissue level classification problem. Our evaluation on these datasets demonstrates that the proposed GenP bioimage ensemble obtains state-of-the-art performance without any ad-hoc dataset tuning of the parameters thereby avoiding any risk of overfitting/overtraining. To reproduce the experiments reported in this paper, the MATLAB code of all the descriptors is available at https://github.com/LorisNanni and https://www.dropbox.com/s/bguw035yrqz0pwp/ElencoCode.docx?dl=0.},
journal = {IEEE/ACM Trans. Comput. Biol. Bioinformatics},
month = {may},
pages = {874–885},
numpages = {12}
}

@article{10.1109/TCBB.2021.3138304,
author = {Ragi, Shankarachary and Rahman, Md Hafizur and Duckworth, Jamison and Jawaharraj, Kalimuthu and Chundi, Parvathi and Gadhamshetty, Venkataramana},
title = {Artificial Intelligence-Driven Image Analysis of Bacterial Cells and Biofilms},
year = {2021},
issue_date = {Jan.-Feb. 2023},
publisher = {IEEE Computer Society Press},
address = {Washington, DC, USA},
volume = {20},
number = {1},
issn = {1545-5963},
url = {https://doi.org/10.1109/TCBB.2021.3138304},
doi = {10.1109/TCBB.2021.3138304},
abstract = {The current study explores an artificial intelligence framework for measuring the structural features from microscopy images of the bacterial biofilms. &lt;italic&gt;Desulfovibrio alaskensis&lt;/italic&gt; G20 (DA-G20) grown on mild steel surfaces is used as a model for sulfate reducing bacteria that are implicated in microbiologically influenced corrosion problems. Our goal is to automate the process of extracting the geometrical properties of the DA-G20 cells from the scanning electron microscopy (SEM) images, which is otherwise a laborious and costly process. These geometric properties are a biofilm phenotype that allow us to understand how the biofilm structurally adapts to the surface properties of the underlying metals, which can lead to better corrosion prevention solutions. We adapt two deep learning models: (a) a deep convolutional neural network (DCNN) model to achieve semantic segmentation of the cells, (d) a mask region-convolutional neural network (Mask R-CNN) model to achieve instance segmentation of the cells. These models are then integrated with moment invariants approach to measure the geometric characteristics of the segmented cells. Our numerical studies confirm that the Mask-RCNN and DCNN methods are 227x and 70x faster respectively, compared to the traditional method of manual identification and measurement of the cell geometric properties by the domain experts.},
journal = {IEEE/ACM Trans. Comput. Biol. Bioinformatics},
month = {dec},
pages = {174–184},
numpages = {11}
}

@article{10.1109/TCBB.2016.2615606,
author = {Borges, Vinicius R. P. and Oliveira, Maria Cristina F. de and Silva, Thais Garcia and Vieira, Armando Augusto Henriques and Hamann, Bernd},
title = {Region Growing for Segmenting Green Microalgae Images},
year = {2018},
issue_date = {January 2018},
publisher = {IEEE Computer Society Press},
address = {Washington, DC, USA},
volume = {15},
number = {1},
issn = {1545-5963},
url = {https://doi.org/10.1109/TCBB.2016.2615606},
doi = {10.1109/TCBB.2016.2615606},
abstract = {We describe a specialized methodology for segmenting 2D microscopy digital images of freshwater green microalgae. The goal is to obtain representative algae shapes to extract morphological features to be employed in a posterior step of taxonomical classification of the species. The proposed methodology relies on the seeded region growing principle and on a fine-tuned filtering preprocessing stage to smooth the input image. A contrast enhancement process then takes place to highlight algae regions on a binary pre-segmentation image. This binary image is also employed to determine where to place the seed points and to estimate the statistical probability distributions that characterize the target regions, i.e., the algae areas and the background, respectively. These preliminary stages produce the required information to set the homogeneity criterion for region growing. We evaluate the proposed methodology by comparing its resulting segmentations with a set of corresponding ground-truth segmentations provided by an expert biologist and also with segmentations obtained with existing strategies. The experimental results show that our solution achieves highly accurate segmentation rates with greater efficiency, as compared with the performance of standard segmentation approaches and with an alternative previous solution, based on level-sets, also specialized to handle this particular problem.},
journal = {IEEE/ACM Trans. Comput. Biol. Bioinformatics},
month = {jan},
pages = {257–270},
numpages = {14}
}

@article{10.1109/TCBB.2005.42,
author = {Demir, Cigdem and Gultekin, S. Humayun and Yener, Bulent},
title = {Learning the Topological Properties of Brain Tumors},
year = {2005},
issue_date = {July 2005},
publisher = {IEEE Computer Society Press},
address = {Washington, DC, USA},
volume = {2},
number = {3},
issn = {1545-5963},
url = {https://doi.org/10.1109/TCBB.2005.42},
doi = {10.1109/TCBB.2005.42},
abstract = {This work presents a graph-based representation (a.k.a., cell-graph) of histopathological images for automated cancer diagnosis by probabilistically assigning a link between a pair of cells (or cell clusters). Since the node set of a cell-graph can include a cluster of cells as well as individual ones, it enables working with low-cost, low-magnification photomicrographs. The contributions of this work are twofold. First, it is shown that without establishing a pairwise spatial relation between the cells (i.e., the edges of a cell-graph), neither the spatial distribution of the cells nor the texture analysis of the images yields accurate results for tissue level diagnosis of brain cancer called malignant glioma. Second, this work defines a set of global metrics by processing the entire cell-graph to capture tissue level information coded into the histopathological images. In this work, the results are obtained on the photomicrographs of 646 archival brain biopsy samples of 60 different patients. It is shown that the global metrics of cell-graphs distinguish cancerous tissues from noncancerous ones with high accuracy (at least 99 percent accuracy for healthy tissues with lower cellular density level, and at least 92 percent accuracy for benign tissues with similar high cellular density level such as nonneoplastic reactive/inflammatory conditions).},
journal = {IEEE/ACM Trans. Comput. Biol. Bioinformatics},
month = {jul},
pages = {262–270},
numpages = {9},
keywords = {Index Terms- Image representation, graph theory, machine learning, medical information systems., model development}
}

@article{10.1145/2700422,
author = {Puglisi, Giovanni and Stanco, Filippo and Barone, Germana and Mazzoleni, Paolo},
title = {Automatic Extraction of Petrographic Features from Pottery of Archaeological Interest},
year = {2015},
issue_date = {May 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {3},
issn = {1556-4673},
url = {https://doi.org/10.1145/2700422},
doi = {10.1145/2700422},
abstract = {The microscopic description of ancient pottery is widely used for the fabric definition, classification and provenance assessment. In most cases, however, the description is qualitative. An improvement of the study of archaeological pottery needs a more objective approach with quantitative analysis. In classical scientific literature, the structural features and mineralogical composition of pottery are carried out on thin sections by means of transmitted polarized light microscope. The determination were obtained through observations with and without cross polarizator (nicols). The quantitative measurements are normally achieved with tedious and time consuming table with point counter. In this article the attention has been focused on the automatic identification of structural and textural components of the potteries through optical microscopy. Image analysis techniques have been then used to automatically classify the image components. Results confirm the effectiveness of the proposed approach: petrographic data collection becomes faster with respect to the traditional method providing also quantitative information useful for fabric recognition.},
journal = {J. Comput. Cult. Herit.},
month = {mar},
articleno = {13},
numpages = {13},
keywords = {Thin section analysis, cultural heritage, image alignment, petrographic features, pottery}
}

@article{10.1145/3592147,
author = {Garces, Elena and Arellano, Victor and Rodriguez-Pardo, Carlos and Pascual-Hernandez, David and Suja, Sergio and Lopez-Moreno, Jorge},
title = {Towards Material Digitization with a Dual-scale Optical System},
year = {2023},
issue_date = {August 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {42},
number = {4},
issn = {0730-0301},
url = {https://doi.org/10.1145/3592147},
doi = {10.1145/3592147},
abstract = {Existing devices for measuring material appearance in spatially-varying samples are limited to a single scale, either micro or mesoscopic. This is a practical limitation when the material has a complex multi-scale structure. In this paper, we present a system and methods to digitize materials at two scales, designed to include high-resolution data in spatially-varying representations at larger scales. We design and build a hemispherical light dome able to digitize flat material samples up to 11x11cm. We estimate geometric properties, anisotropic reflectance and transmittance at the microscopic level using polarized directional lighting with a single orthogonal camera. Then, we propagate this structured information to the mesoscale, using a neural network trained with the data acquired by the device and image-to-image translation methods. To maximize the compatibility of our digitization, we leverage standard BSDF models commonly adopted in the industry. Through extensive experiments, we demonstrate the precision of our device and the quality of our digitization process using a set of challenging real-world material samples and validation scenes. Further, we demonstrate the optical resolution and potential of our device for acquiring more complex material representations by capturing microscopic attributes which affect the global appearance: we characterize the properties of textile materials such as the yarn twist or the shape of individual fly-out fibers. We also release the SEDDIDOME dataset of materials, including raw data captured by the machine and optimized parameteres.},
journal = {ACM Trans. Graph.},
month = {jul},
articleno = {152},
numpages = {13},
keywords = {digitization, capture system, appearance capture}
}

@article{10.1109/TCBB.2023.3247957,
author = {Witmer, Adam and Theagarajan, Rajkumar and Bhanu, Bir},
title = {Triplet-Net Classification of Contiguous Stem Cell Microscopy Images},
year = {2023},
issue_date = {May-June 2023},
publisher = {IEEE Computer Society Press},
address = {Washington, DC, USA},
volume = {20},
number = {3},
issn = {1545-5963},
url = {https://doi.org/10.1109/TCBB.2023.3247957},
doi = {10.1109/TCBB.2023.3247957},
abstract = {Cellular microscopy imaging is a common form of data acquisition for biological experimentation. Observation of gray-level morphological features allows for the inference of useful biological information such as cellular health and growth status. Cellular colonies can contain multiple cell types, making colony level classification very difficult. Additionally, cell types growing in a hierarchical, downstream fashion, can often look visually similar, although biologically distinct. In this paper, it is determined empirically that traditional deep Convolutional Neural Networks (CNN) and classical object recognition techniques are not sufficient to distinguish between these subtle visual differences, resulting in misclassifications. Instead, Triplet-net CNN learning is employed in a hierarchical classification scheme to improve the ability of the model to discern distinct, fine-grain features of two commonly confused morphological image-patch classes, namely Dense and Spread colonies. The Triplet-net method improves classification accuracy over a four-class deep neural network by &lt;inline-formula&gt;&lt;tex-math notation="LaTeX"&gt;$sim$&lt;/tex-math&gt;&lt;alternatives&gt;&lt;mml:math&gt;&lt;mml:mo&gt;∼&lt;/mml:mo&gt;&lt;/mml:math&gt;&lt;inline-graphic xlink:href="witmer-ieq1-3247957.gif"/&gt;&lt;/alternatives&gt;&lt;/inline-formula&gt; 3&lt;inline-formula&gt;&lt;tex-math notation="LaTeX"&gt;$%$&lt;/tex-math&gt;&lt;alternatives&gt;&lt;mml:math&gt;&lt;mml:mo&gt;%&lt;/mml:mo&gt;&lt;/mml:math&gt;&lt;inline-graphic xlink:href="witmer-ieq2-3247957.gif"/&gt;&lt;/alternatives&gt;&lt;/inline-formula&gt;, a value that was determined to be statistically significant, as well as existing state-of-the-art image patch classification approaches and standard template matching. These findings allow for the accurate classification of multi-class cell colonies with contiguous boundaries, and increased reliability and efficiency of automated, high-throughput experimental quantification using non-invasive microscopy.},
journal = {IEEE/ACM Trans. Comput. Biol. Bioinformatics},
month = {feb},
pages = {2314–2327},
numpages = {14}
}

@article{10.1145/3130800.3130840,
author = {Werner, Sebastian and Velinov, Zdravko and Jakob, Wenzel and Hullin, Matthias B.},
title = {Scratch iridescence: wave-optical rendering of diffractive surface structure},
year = {2017},
issue_date = {December 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {36},
number = {6},
issn = {0730-0301},
url = {https://doi.org/10.1145/3130800.3130840},
doi = {10.1145/3130800.3130840},
abstract = {The surface of metal, glass and plastic objects is often characterized by microscopic scratches caused by manufacturing and/or wear. A closer look onto such scratches reveals iridescent colors with a complex dependency on viewing and lighting conditions. The physics behind this phenomenon is well understood; it is caused by diffraction of the incident light by surface features on the order of the optical wavelength. Existing analytic models are able to reproduce spatially unresolved microstructure such as the iridescent appearance of compact disks and similar materials. Spatially resolved scratches, on the other hand, have proven elusive due to the highly complex wave-optical light transport simulations needed to account for their appearance. In this paper, we propose a wave-optical shading model based on non-paraxial scalar diffraction theory to render this class of effects. Our model expresses surface roughness as a collection of line segments. To shade a point on the surface, the individual diffraction patterns for contributing scratch segments are computed analytically and superimposed coherently. This provides natural transitions from localized glint-like iridescence to smooth BRDFs representing the superposition of many reflections at large viewing distances. We demonstrate that our model is capable of recreating the overall appearance as well as characteristic detail effects observed on real-world examples.},
journal = {ACM Trans. Graph.},
month = {nov},
articleno = {207},
numpages = {14},
keywords = {SVBRDF, diffraction, iridescence}
}

@article{10.1109/TCBB.2016.2591520,
author = {Ding, Yuchun and Pardon, Marie Christine and Agostini, Alessandra and Faas, Henryk and Duan, Jinming and Ward, Wil O C and Easton, Felicity and Auer, Dorothee and Bai, Li},
title = {Novel Methods for Microglia Segmentation, Feature Extraction, and Classification},
year = {2017},
issue_date = {November 2017},
publisher = {IEEE Computer Society Press},
address = {Washington, DC, USA},
volume = {14},
number = {6},
issn = {1545-5963},
url = {https://doi.org/10.1109/TCBB.2016.2591520},
doi = {10.1109/TCBB.2016.2591520},
abstract = {Segmentation and analysis of histological images provides a valuable tool to gain insight into the biology and function of microglial cells in health and disease. Common image segmentation methods are not suitable for inhomogeneous histology image analysis and accurate classification of microglial activation states has remained a challenge. In this paper, we introduce an automated image analysis framework capable of efficiently segmenting microglial cells from histology images and analyzing their morphology. The framework makes use of variational methods and the fast-split Bregman algorithm for image denoising and segmentation, and of multifractal analysis for feature extraction to classify microglia by their activation states. Experiments show that the proposed framework is accurate and scalable to large datasets and provides a useful tool for the study of microglial biology.},
journal = {IEEE/ACM Trans. Comput. Biol. Bioinformatics},
month = {nov},
pages = {1366–1377},
numpages = {12}
}

@article{10.1145/2010324.1964941,
author = {Johnson, Micah K. and Cole, Forrester and Raj, Alvin and Adelson, Edward H.},
title = {Microgeometry capture using an elastomeric sensor},
year = {2011},
issue_date = {July 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {30},
number = {4},
issn = {0730-0301},
url = {https://doi.org/10.1145/2010324.1964941},
doi = {10.1145/2010324.1964941},
abstract = {We describe a system for capturing microscopic surface geometry. The system extends the retrographic sensor [Johnson and Adelson 2009] to the microscopic domain, demonstrating spatial resolution as small as 2 microns. In contrast to existing microgeometry capture techniques, the system is not affected by the optical characteristics of the surface being measured---it captures the same geometry whether the object is matte, glossy, or transparent. In addition, the hardware design allows for a variety of form factors, including a hand-held device that can be used to capture high-resolution surface geometry in the field. We achieve these results with a combination of improved sensor materials, illumination design, and reconstruction algorithm, as compared to the original sensor of Johnson and Adelson [2009].},
journal = {ACM Trans. Graph.},
month = {jul},
articleno = {46},
numpages = {8},
keywords = {geometry, material, microstructure, texture}
}

@article{10.1145/3610921,
author = {Hu, Yongquan and Yeo, Hui-Shyong and Yuan, Mingyue and Fan, Haoran and Elvitigala, Don Samitha and Hu, Wen and Quigley, Aaron},
title = {MicroCam: Leveraging Smartphone Microscope Camera for Context-Aware Contact Surface Sensing},
year = {2023},
issue_date = {September 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {3},
url = {https://doi.org/10.1145/3610921},
doi = {10.1145/3610921},
abstract = {The primary focus of this research is the discreet and subtle everyday contact interactions between mobile phones and their surrounding surfaces. Such interactions are anticipated to facilitate mobile context awareness, encompassing aspects such as dispensing medication updates, intelligently switching modes (e.g., silent mode), or initiating commands (e.g., deactivating an alarm). We introduce MicroCam, a contact-based sensing system that employs smartphone IMU data to detect the routine state of phone placement and utilizes a built-in microscope camera to capture intricate surface details. In particular, a natural dataset is collected to acquire authentic surface textures in situ for training and testing. Moreover, we optimize the deep neural network component of the algorithm, based on continual learning, to accurately discriminate between object categories (e.g., tables) and material constituents (e.g., wood). Experimental results highlight the superior accuracy, robustness and generalization of the proposed method. Lastly, we conducted a comprehensive discussion centered on our prototype, encompassing topics such as system performance and potential applications and scenarios.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = {sep},
articleno = {98},
numpages = {28},
keywords = {Sensing, macro-camera, microscope camera, mobile interaction, surface sensing}
}

@article{10.1145/3604550,
author = {Liu, Yaochen and Li, Qiuchi and Wang, Benyou and Zhang, Yazhou and Song, Dawei},
title = {A Survey of Quantum-cognitively Inspired Sentiment Analysis Models},
year = {2023},
issue_date = {January 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {56},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/3604550},
doi = {10.1145/3604550},
abstract = {Quantum theory, originally proposed as a physical theory to describe the motions of microscopic particles, has been applied to various non-physics domains involving human cognition and decision-making that are inherently uncertain and exhibit certain non-classical, quantum-like characteristics. Sentiment analysis is a typical example of such domains. In the last few years, by leveraging the modeling power of quantum probability (a non-classical probability stemming from quantum mechanics methodology) and deep neural networks, a range of novel quantum-cognitively inspired models for sentiment analysis have emerged and performed well. This survey presents a timely overview of the latest developments in this fascinating cross-disciplinary area. We first provide a background of quantum probability and quantum cognition at a theoretical level, analyzing their advantages over classical theories in modeling the cognitive aspects of sentiment analysis. Then, recent quantum-cognitively inspired models are introduced and discussed in detail, focusing on how they approach the key challenges of the sentiment analysis task. Finally, we discuss the limitations of the current research and highlight future research directions.},
journal = {ACM Comput. Surv.},
month = {aug},
articleno = {15},
numpages = {37},
keywords = {Quantum-cognitively inspired models, non-classical probability from quantum mechanics methodology, sentiment analysis, sarcasm detection, emotion recognition}
}

@article{10.1145/3563695,
author = {Sakalis, Christos and Kaxiras, Stefanos and Sj\"{a}lander, Magnus},
title = {Delay-on-Squash: Stopping Microarchitectural Replay Attacks in Their Tracks},
year = {2022},
issue_date = {March 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {20},
number = {1},
issn = {1544-3566},
url = {https://doi.org/10.1145/3563695},
doi = {10.1145/3563695},
abstract = {MicroScope and other similar microarchitectural replay attacks take advantage of the characteristics of speculative execution to trap the execution of the victim application in a loop, enabling the attacker to amplify a side-channel attack by executing it indefinitely. Due to the nature of the replay, it can be used to effectively attack software that are shielded against replay, even under conditions where a side-channel attack would not be possible (e.g., in secure enclaves). At the same time, unlike speculative side-channel attacks, microarchitectural replay attacks can be used to amplify the correct path of execution, rendering many existing speculative side-channel defenses ineffective. In this work, we generalize microarchitectural replay attacks beyond MicroScope and present an efficient defense against them. We make the observation that such attacks rely on repeated squashes of so-called “replay handles” and that the instructions causing the side-channel must reside in the same reorder buffer window as the handles. We propose Delay-on-Squash, a hardware-only technique for tracking squashed instructions and preventing them from being replayed by speculative replay handles. Our evaluation shows that it is possible to achieve full security against microarchitectural replay attacks with very modest hardware requirements while still maintaining 97% of the insecure baseline performance.},
journal = {ACM Trans. Archit. Code Optim.},
month = {nov},
articleno = {9},
numpages = {24},
keywords = {Microarchitecture, side-channels, security, replay attacks}
}

@article{10.1109/TCBB.2022.3218590,
author = {Das, Pradeep Kumar and Sahoo, Biswajeet and Meher, Sukadev},
title = {An Efficient Detection and Classification of Acute Leukemia Using Transfer Learning and Orthogonal Softmax Layer-Based Model},
year = {2022},
issue_date = {May-June 2023},
publisher = {IEEE Computer Society Press},
address = {Washington, DC, USA},
volume = {20},
number = {3},
issn = {1545-5963},
url = {https://doi.org/10.1109/TCBB.2022.3218590},
doi = {10.1109/TCBB.2022.3218590},
abstract = {For the early diagnosis of hematological disorders like blood cancer, microscopic analysis of blood cells is very important. Traditional deep CNNs lead to overfitting when it receives small medical image datasets such as ALLIDB1, ALLIDB2, and ASH. This paper proposes a new and effective model for classifying and detecting Acute Lymphoblastic Leukemia (ALL) or Acute Myelogenous Leukemia (AML) that delivers excellent performance in small medical datasets. Here, we have proposed a novel Orthogonal SoftMax Layer (OSL)-based Acute Leukemia detection model that consists of ResNet 18-based deep feature extraction followed by efficient OSL-based classification. Here, OSL is integrated with the ResNet18 to improve the classification performance by making the weight vectors orthogonal to each other. Hence, it integrates ResNet benefits (residual learning and identity mapping) with the benefits of OSL-based classification (improvement of feature discrimination capability and computational efficiency). Furthermore, we have introduced extra dropout and ReLu layers in the architecture to achieve a faster network with enhanced performance. The performance verification is performed on standard ALLIDB1, ALLIDB2, and &lt;inline-formula&gt;&lt;tex-math notation="LaTeX"&gt;$ C_{N}MC_{2}019$&lt;/tex-math&gt;&lt;alternatives&gt;&lt;mml:math&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;C&lt;/mml:mi&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;mml:mi&gt;N&lt;/mml:mi&gt;&lt;mml:mi&gt;M&lt;/mml:mi&gt;&lt;mml:mi&gt;C&lt;/mml:mi&gt;&lt;mml:mo&gt;_&lt;/mml:mo&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;mml:mn&gt;019&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;&lt;inline-graphic xlink:href="das-ieq1-3218590.gif"/&gt;&lt;/alternatives&gt;&lt;/inline-formula&gt; datasets for efficient ALL detection and ASH dataset for effective AML detection. The experimental performance demonstrates the superiority of the proposed model over other compairing models.},
journal = {IEEE/ACM Trans. Comput. Biol. Bioinformatics},
month = {nov},
pages = {1817–1828},
numpages = {12}
}

@article{10.1007/s00779-022-01687-9,
author = {Saeed, R. A. and Recupero, Diego Reforgiato and Remagnino, Paolo},
title = {Modelling group dynamics for crowd simulations},
year = {2022},
issue_date = {Oct 2022},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {26},
number = {5},
issn = {1617-4909},
url = {https://doi.org/10.1007/s00779-022-01687-9},
doi = {10.1007/s00779-022-01687-9},
abstract = {This paper investigates a new method to simulate pedestrian crowd movement in a large and complex virtual environment, representing a public space such as a shopping mall. To demonstrate pedestrian dynamics, we consider groups of pedestrians of different size, sharing a crowded environment. A pedestrian has its own characteristics, such as gender, age, position, velocity, and energy. The proposed method uses a multi-group microscopic model to generate real-time trajectories for all people moving in the defined virtual environment. Additionally, a dynamic model is introduced for modelling group behaviour. Based on the proposed method, all pedestrians in each group can continuously adjust their attributes and optimize their path towards the desired visiting targets, while avoiding obstacles and other pedestrians. Simulation results show that the proposed method can describe a realistic simulation of dynamic behaviour.},
journal = {Personal Ubiquitous Comput.},
month = {jul},
pages = {1299–1319},
numpages = {21},
keywords = {Crowd dynamics, Multi-group microscopic model, Agent-based model, Pedestrian movement}
}

@article{10.1145/3472293,
author = {Steinberg, Shlomi and Yan, Ling-Qi},
title = {Rendering of Subjective Speckle Formed by Rough Statistical Surfaces},
year = {2022},
issue_date = {February 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {41},
number = {1},
issn = {0730-0301},
url = {https://doi.org/10.1145/3472293},
doi = {10.1145/3472293},
abstract = {Tremendous effort has been extended by the computer graphics community to advance the level of realism of material appearance reproduction by incorporating increasingly more advanced techniques. We are now able to re-enact the complicated interplay between light and microscopic surface features—scratches, bumps and other imperfections—in a visually convincing fashion. However, diffractive patterns arise even when no explicitly defined features are present: Any random surface will act as a diffracting aperture and its statistics heavily influence the statistics of the diffracted wave fields. Nonetheless, the problem of rendering diffraction effects induced by surfaces that are defined purely statistically remains wholly unexplored. We present a thorough derivation, from core optical principles, of the intensity of the scattered fields that arise when a natural, partially coherent light source illuminates a random surface. We follow with a probability theory analysis of the statistics of those fields and present our rendering algorithm. All of our derivations are formally proven and verified numerically as well. Our method is the first to render diffraction effects produced by a surface described statistically only, and bridges the theoretical gap between contemporary surface modelling and rendering.},
journal = {ACM Trans. Graph.},
month = {feb},
articleno = {2},
numpages = {23},
keywords = {Diffractions, wave optics, speckle, scatter, iridescence, statistical surfaces, appearance reproduction, coherence, monte carlo}
}

@article{10.1145/3480136,
author = {Daniel, Beatr\'{\i}z Cabrero and Marques, Ricardo and Hoyet, Ludovic and Pettr\'{e}, Julien and Blat, Josep},
title = {A Perceptually-Validated Metric for Crowd Trajectory Quality Evaluation},
year = {2021},
issue_date = {September 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {4},
number = {3},
url = {https://doi.org/10.1145/3480136},
doi = {10.1145/3480136},
abstract = {Simulating crowds requires controlling a very large number of trajectories and is usually performed using crowd motion algorithms for which appropriate parameter values need to be found. The study of the relation between parametric values for simulation techniques and the quality of the resulting trajectories has been studied either through perceptual experiments or by comparison with real crowd trajectories. In this paper, we integrate both strategies. A quality metric, QF, is proposed to abstract from reference data while capturing the most salient features that affect the perception of trajectory realism. QF weights and combines cost functions that are based on several individual, local and global properties of trajectories. These trajectory features are selected from the literature and from interviews with experts. To validate the capacity of QF to capture perceived trajectory quality, we conduct an online experiment that demonstrates the high agreement between the automatic quality score and non-expert users. To further demonstrate the usefulness of QF, we use it in a data-free parameter tuning application able to tune any parametric microscopic crowd simulation model that outputs independent trajectories for characters. The learnt parameters for the tuned crowd motion model maintain the influence of the reference data which was used to weight the terms of QF.},
journal = {Proc. ACM Comput. Graph. Interact. Tech.},
month = {sep},
articleno = {42},
numpages = {18},
keywords = {automatic simulation evaluation, perception experiment, trajectory quality}
}

@article{10.1109/TCBB.2021.3079216,
author = {Jia, Xibin and Sun, Zheng and Mi, Qing and Yang, Zhenghan and Yang, Dawei},
title = {A Multimodality-Contribution-Aware TripNet for Histologic Grading of Hepatocellular Carcinoma},
year = {2021},
issue_date = {July-Aug. 2022},
publisher = {IEEE Computer Society Press},
address = {Washington, DC, USA},
volume = {19},
number = {4},
issn = {1545-5963},
url = {https://doi.org/10.1109/TCBB.2021.3079216},
doi = {10.1109/TCBB.2021.3079216},
abstract = {Hepatocellular carcinoma (HCC) is a type of primary liver malignant tumor with a high recurrence rate and poor prognosis even undergoing resection or transplantation. Accurate discrimination of the histologic grades of HCC plays a critical role in the management and therapy of HCC patients. In this paper, we discuss a deep learning-based diagnostic model for HCC histologic grading with multimodal Magnetic Resonance Imaging (MRI) images to overcome the problem of limited well-annotated data and extract the discriminated fusion feature referring to the clinical diagnosis experience of radiologists. Accordingly, we propose a novel Multimodality-Contribution-Aware TripNet (MCAT) based on the metric learning and the attention-aware weighted multimodal fusion. The novelty of the method lies in the multimodality small-shot learning architecture designation and the multimodality adaptive weighted computing scheme. The comprehensive experiments are done on the clinic dataset with the well-annotation of lesion location by the professional radiologist. The experimental results show that our proposed MCAT is not only able to achieve acceptable quantitative measuring of HCC histologic grading based on the MRI sequences with small cases but also outperforms previous models in HCC histologic grading, reaching an accuracy of 84 percent, a sensitivity of 87 percent and precision of 89 percent.},
journal = {IEEE/ACM Trans. Comput. Biol. Bioinformatics},
month = {may},
pages = {2003–2016},
numpages = {14}
}

@article{10.1109/TCBB.2020.3041723,
author = {Madhumita and Paul, Sushmita},
title = {A Feature Weighting-Assisted Approach for Cancer Subtypes Identification From Paired Expression Profiles},
year = {2020},
issue_date = {May-June 2022},
publisher = {IEEE Computer Society Press},
address = {Washington, DC, USA},
volume = {19},
number = {3},
issn = {1545-5963},
url = {https://doi.org/10.1109/TCBB.2020.3041723},
doi = {10.1109/TCBB.2020.3041723},
abstract = {Identification of cancer subtypes is critically important for understanding the heterogeneity present in tumors. Projects like The Cancer Genome Atlas (TCGA), have made available the data-sets containing expression profiles of multiple types of biomarkers across the same set of samples. Availability of these types of data-sets help in capturing heterogeneity underlying, complex biological processes and phenotypes. Further, by integrating information from multiple sources, homogeneous groups for cancer can be identified. However, there is a lack of computational approaches to identify histological subtypes among the patients suffering from different types of cancers. Assigning weight to the biomarkers prior to the integration of multiple information sources for the same set of samples can play an important role in cancer subtypes identification, which has not been explored previously. Sub-typing of cancers can help in analyzing shared molecular profiles between different histological subtypes of solid tumors. This can further help in designing appropriate therapies and treatments. A novel method for feature weighting based on robust regression fit is developed in this study. This method assigns a weight to every biomarker on the basis of variability present across the samples. Later, this weight is utilized to find similarity between patients individually from each of the information sources. In this study, the two information sources that have been utilized are miRNA and mRNA expression profiles across the same set of samples. Patient-similarity networks, that are generated from each of the expression profiles are then integrated using the approach of Similarity Network Fusion. Finally, Spectral clustering is applied on the fused network to identify similar groups of patients that represent a cancer subtype. To establish the efficiency of the proposed approach, it has been applied to three types of cancer data-sets and is also compared with the other existing methods.},
journal = {IEEE/ACM Trans. Comput. Biol. Bioinformatics},
month = {dec},
pages = {1403–1414},
numpages = {12}
}

@article{10.1145/3345318,
author = {Tripathi, Suvidha and Singh, Satish Kumar},
title = {Cell Nuclei Classification in Histopathological Images using Hybrid OLConvNet},
year = {2020},
issue_date = {January 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {1s},
issn = {1551-6857},
url = {https://doi.org/10.1145/3345318},
doi = {10.1145/3345318},
abstract = {Computer-aided histopathological image analysis for cancer detection is a major research challenge in the medical domain. Automatic detection and classification of nuclei for cancer diagnosis impose a lot of challenges in developing state-of-the-art algorithms due to the heterogeneity of cell nuclei and dataset variability. Recently, a multitude of classification algorithms have used complex deep learning models for their dataset. However, most of these methods are rigid, and their architectural arrangement suffers from inflexibility and non-interpretability. In this research article, we have proposed a hybrid and flexible deep learning architecture OLConvNet that integrates the interpretability of traditional object-level features and generalization of deep learning features by using a shallower Convolutional Neural Network (CNN) named as CNN3L. CNN3L reduces the training time by training fewer parameters and hence eliminating space constraints imposed by deeper algorithms. We used F1-score and multiclass Area Under the Curve (AUC) performance parameters to compare the results. To further strengthen the viability of our architectural approach, we tested our proposed methodology with state-of-the-art deep learning architectures AlexNet, VGG16, VGG19, ResNet50, InceptionV3, and DenseNet121 as backbone networks. After a comprehensive analysis of classification results from all four architectures, we observed that our proposed model works well and performs better than contemporary complex algorithms.},
journal = {ACM Trans. Multimedia Comput. Commun. Appl.},
month = {mar},
articleno = {32},
numpages = {22},
keywords = {Deep learning, cell nuclei classification, class balancing, convolutional neural networks, histopathological images, hybrid networks, multi layer perceptron, object-level features, transfer learning}
}

@article{10.1109/TCBB.2019.2936851,
author = {Liu, Min and Liu, Yalan and Qian, Weili and Wang, Yaonan},
title = {DeepSeed Local Graph Matching for Densely Packed Cells Tracking},
year = {2019},
issue_date = {May-June 2021},
publisher = {IEEE Computer Society Press},
address = {Washington, DC, USA},
volume = {18},
number = {3},
issn = {1545-5963},
url = {https://doi.org/10.1109/TCBB.2019.2936851},
doi = {10.1109/TCBB.2019.2936851},
abstract = {The tracking of densely packed plant cells across microscopy image sequences is very challenging, because their appearance change greatly over time. A local graph matching algorithm was proposed to track such cells by exploiting the tight spatial topology of neighboring cells, and then an iterative searching strategy was used to grow the correspondence from a seed cell pair. Thus, the performance of the existing tracking approach heavily relies on the robustness of finding seed cell pair. However, the existing local graph matching algorithm cannot guarantee the correctness of the seed cell pair, especially in unregistered image sequences or image sequences with large time intervals. In this paper, we propose a DeepSeed local graph matching model to find seed cell pair robustly, by combining local graph matching and CNN-based similarity learning, which uses cells’ spatial-temporal contextual information and cell pairs’ similarity information. The CNN-based similarity learning is designed to learn cells’ deep feature and measure cell pairs’ similarity. Compared with the existing plant cell matching methods, the experimental results show that the DeepSeed local graph matching method can track most cells in unregistered image sequences. Moreover, the DeepSeed tracking algorithm can accurately track cells across image sequences with large time intervals.},
journal = {IEEE/ACM Trans. Comput. Biol. Bioinformatics},
month = {aug},
pages = {1060–1069},
numpages = {10}
}

@article{10.1145/3185516,
author = {Hossain, H. M. Sajjad and Ramamurthy, Sreenivasan R. and Khan, Md Abdullah Al Hafiz and Roy, Nirmalya},
title = {An Active Sleep Monitoring Framework Using Wearables},
year = {2018},
issue_date = {September 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {3},
issn = {2160-6455},
url = {https://doi.org/10.1145/3185516},
doi = {10.1145/3185516},
abstract = {Sleep is the most important aspect of healthy and active living. The right amount of sleep at the right time helps an individual to protect his or her physical, mental, and cognitive health and maintain his or her quality of life. The most durative of the Activities of Daily Living (ADL), sleep has a major synergic influence on a person’s fuctional, behavioral, and cognitive health. A deep understanding of sleep behavior and its relationship with its physiological signals, and contexts (such as eye or body movements), is necessary to design and develop a robust intelligent sleep monitoring system. In this article, we propose an intelligent algorithm to detect the microscopic states of sleep that fundamentally constitute the components of good and bad sleeping behaviors and thus help shape the formative assessment of sleep quality. Our initial analysis includes the investigation of several classification techniques to identify and correlate the relationship of microscopic sleep states with overall sleep behavior. Subsequently, we also propose an online algorithm based on change point detection to process and classify the microscopic sleep states. We also develop a lightweight version of the proposed algorithm for real-time sleep monitoring, recognition, and assessment at scale. For a larger deployment of our proposed model across a community of individuals, we propose an active-learning-based methodology to reduce the effort of ground-truth data collection and labeling. Finally, we evaluate the performance of our proposed algorithms on real data traces and demonstrate the efficacy of our models for detecting and assessing the fine-grained sleep states beyond an individual.},
journal = {ACM Trans. Interact. Intell. Syst.},
month = {jul},
articleno = {22},
numpages = {30},
keywords = {Sleep monitoring, active learning, crowdsourcing, gradient classifier, wearable technology}
}

@article{10.1109/TCBB.2017.2677907,
author = {Shao, Wei and Liu, Mingxia and Xu, Ying-Ying and Shen, Hong-Bin and Zhang, Daoqiang},
title = {An Organelle Correlation-Guided Feature Selection Approach for Classifying Multi-Label Subcellular Bio-Images},
year = {2018},
issue_date = {May 2018},
publisher = {IEEE Computer Society Press},
address = {Washington, DC, USA},
volume = {15},
number = {3},
issn = {1545-5963},
url = {https://doi.org/10.1109/TCBB.2017.2677907},
doi = {10.1109/TCBB.2017.2677907},
abstract = {Nowadays, with the advances in microscopic imaging, accurate classification of bioimage-based protein subcellular location pattern has attracted as much attention as ever. One of the basic challenging problems is how to select the useful feature components among thousands of potential features to describe the images. This is not an easy task especially considering there is a high ratio of multi-location proteins. Existing feature selection methods seldom take the correlation among different cellular compartments into consideration, and thus may miss some features that will be co-important for several subcellular locations. To deal with this problem, we make use of the important structural correlation among different cellular compartments and propose an organelle structural correlation regularized feature selection method CSF Common-Sets of Features in this paper. We formulate the multi-label classification problem by adopting a group-sparsity regularizer to select common subsets of relevant features from different cellular compartments. In addition, we also add a cell structural correlation regularized Laplacian term, which utilizes the prior biological structural information to capture the intrinsic dependency among different cellular compartments. The CSF provides a new feature selection strategy for multi-label bio-image subcellular pattern classifications, and the experimental results also show its superiority when comparing with several existing&nbsp;algorithms.},
journal = {IEEE/ACM Trans. Comput. Biol. Bioinformatics},
month = {may},
pages = {828–838},
numpages = {11}
}

@article{10.1007/s00779-017-1031-3,
author = {Heinrichs, Matthias and Krajzewicz, Daniel and Cyganski, Rita and Schmidt, Antje},
title = {Introduction of car sharing into existing car fleets in microscopic travel demand modelling},
year = {2017},
issue_date = {December  2017},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {21},
number = {6},
issn = {1617-4909},
url = {https://doi.org/10.1007/s00779-017-1031-3},
doi = {10.1007/s00779-017-1031-3},
abstract = {Microscopic travel demand models take the characteristics of every individual person of the modelled population into account for computing the travel demand for the modelled region. Car sharing is an old concept, but the combination of a car sharing fleet parked in a public space with smartphone services to find available cars nearby offers a new mobility service. It enables people to use a fleet operator's cars by providing individual mobility on demand. However, integrating this mobility option into microscopic travel demand models still is a difficult task due to a lack of data. This paper shows an integrated approach to model car sharing as a new mode for transport within a travel demand model using disaggregated car fleets with car-specific attributes. The necessary parameters for mode choice are estimated from various surveys and integrated into an existing multinominal logit model. The proposed work is used to simulate the travel demand of a synthetic population for the German capital of Berlin. A comparison with the survey results shows that the proposed integration of car sharing meets the real-world data. Furthermore, it is shown that the mode choice reacts well for access restrictions for specific car segments and local accessibility influencing the trip lengths.},
journal = {Personal Ubiquitous Comput.},
month = {dec},
pages = {1055–1065},
numpages = {11},
keywords = {Agent-based modelling, Car fleet, Car sharing, Disaggregated cars, Microscopic modelling, Travel demand}
}

@article{10.1145/3072959.3073621,
author = {Holzschuch, Nicolas and Pacanowski, Romain},
title = {A two-scale microfacet reflectance model combining reflection and diffraction},
year = {2017},
issue_date = {August 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {36},
number = {4},
issn = {0730-0301},
url = {https://doi.org/10.1145/3072959.3073621},
doi = {10.1145/3072959.3073621},
abstract = {Adequate reflectance models are essential for the production of photorealistic images. Microfacet reflectance models predict the appearance of a material at the macroscopic level based on microscopic surface details. They provide a good match with measured reflectance in some cases, but not always. This discrepancy between the behavior predicted by microfacet models and the observed behavior has puzzled researchers for a long time. In this paper, we show that diffraction effects in the micro-geometry provide a plausible explanation. We describe a two-scale reflectance model, separating between geometry details much larger than wavelength and those of size comparable to wavelength. The former model results in the standard Cook-Torrance model. The latter model is responsible for diffraction effects. Diffraction effects at the smaller scale are convolved by the micro-geometry normal distribution. The resulting two-scale model provides a very good approximation to measured reflectances.},
journal = {ACM Trans. Graph.},
month = {jul},
articleno = {66},
numpages = {12},
keywords = {BRDF, diffraction, material models}
}

@article{10.1109/TCBB.2015.2415787,
author = {Zhang, Fa and Chen, Yu and Ren, Fei and Wang, Xuan and Liu, Zhiyong and Wan, Xiaohua},
title = {A Two-Phase Improved Correlation Method for Automatic Particle Selection in Cryo-EM},
year = {2017},
issue_date = {March 2017},
publisher = {IEEE Computer Society Press},
address = {Washington, DC, USA},
volume = {14},
number = {2},
issn = {1545-5963},
url = {https://doi.org/10.1109/TCBB.2015.2415787},
doi = {10.1109/TCBB.2015.2415787},
abstract = {Particle selection from cryo-electron microscopy Cryo-EM images is very important for high-resolution reconstruction of macromolecular structure. The methods of particle selection can be roughly grouped into two classes, template-matching methods and feature-based methods. In general, template-matching methods usually generate better results than feature-based methods. However, the accuracy of template-matching methods is restricted by the noise and low contrast of Cryo-EM images. Moreover, the processing speed of template-matching methods, restricted by the random orientation of particles, further limits their practical applications. In this paper, combining the advantages of feature-based methods and template-matching methods, we present a two-phase improved correlation method for automatic, fast particle selection. In Phase I, we generate a preliminary particle set using rotation-invariant features of particles. In Phase II, we filter the preliminary particle set using a correlation method to reduce the interference of the high noise background and improve the precision of particle selection. We apply several optimization strategies, including a modified adaboost algorithm, Divide and Conquer technique, cascade strategy and graphics processing unit parallel technique, to improve feature recognition ability and reduce processing time. In addition, we developed two correlation score functions for different correlation situations. Experimental results on the benchmark of Cryo-EM images show that our method can improve the accuracy and processing speed of particle selection significantly.},
journal = {IEEE/ACM Trans. Comput. Biol. Bioinformatics},
month = {mar},
pages = {316–325},
numpages = {10}
}

@article{10.1145/3026794,
author = {Zhang, Ting and Duerstock, Bradley S. and Wachs, Juan P.},
title = {Multimodal Perception of Histological Images for Persons Who Are Blind or Visually Impaired},
year = {2017},
issue_date = {September 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {9},
number = {3},
issn = {1936-7228},
url = {https://doi.org/10.1145/3026794},
doi = {10.1145/3026794},
abstract = {Lack of suitable substitute assistive technology is a roadblock for students and scientists who are blind or visually impaired (BVI) from advancing in careers in science, technology, engineering, and mathematics (STEM) fields. It is challenging for persons who are BVI to interpret real-time visual scientific data which is commonly generated during lab experimentation, such as performing light microscopy, spectrometry, and observing chemical reactions. To address this problem, a real-time multimodal image perception system was developed to allow standard laboratory blood smear images to be perceived by BVI individuals by employing a combination of auditory, haptic, and vibrotactile feedback. These sensory feedback modalities were used to convey visual information through alternative perceptual channels, thus creating a palette of multimodal, sensory information. Two sets of image features of interest (primary and peripheral features) were applied to characterize images. A Bayesian network was applied to construct causal relations between these two groups of features. In order to match primary features with sensor modalities, two methods were conceived. Experimental results confirmed that this real-time approach produced higher accuracy in recognizing and analyzing objects within images compared to conventional tactile images.},
journal = {ACM Trans. Access. Comput.},
month = {jan},
articleno = {7},
numpages = {27},
keywords = {Sensorial substitution, blind or visually impaired, haptics, image perception, multi-modality, vibrotactile}
}

@article{10.1145/2898363,
author = {Ramamohanarao, Kotagiri and Xie, Hairuo and Kulik, Lars and Karunasekera, Shanika and Tanin, Egemen and Zhang, Rui and Khunayn, Eman Bin},
title = {SMARTS: Scalable Microscopic Adaptive Road Traffic Simulator},
year = {2016},
issue_date = {March 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {2},
issn = {2157-6904},
url = {https://doi.org/10.1145/2898363},
doi = {10.1145/2898363},
abstract = {Microscopic traffic simulators are important tools for studying transportation systems as they describe the evolution of traffic to the highest level of detail. A major challenge to microscopic simulators is the slow simulation speed due to the complexity of traffic models. We have developed the Scalable Microscopic Adaptive Road Traffic Simulator (SMARTS), a distributed microscopic traffic simulator that can utilize multiple independent processes in parallel. SMARTS can perform fast large-scale simulations. For example, when simulating 1 million vehicles in an area the size of Melbourne, the system runs 1.14 times faster than real time with 30 computing nodes and 0.2s simulation timestep. SMARTS supports various driver models and traffic rules, such as the car-following model and lane-changing model, which can be driver dependent. It can simulate multiple vehicle types, including bus and tram. The simulator is equipped with a wide range of features that help to customize, calibrate, and monitor simulations. Simulations are accurate and confirm with real traffic behaviours. For example, it achieves 79.1% accuracy in predicting traffic on a 10km freeway 90 minutes into the future. The simulator can be used for predictive traffic advisories as well as traffic management decisions as simulations complete well ahead of real time. SMARTS can be easily deployed to different operating systems as it is developed with the standard Java libraries.},
journal = {ACM Trans. Intell. Syst. Technol.},
month = {dec},
articleno = {26},
numpages = {22},
keywords = {Microscopic traffic simulation, distributed computing}
}

@article{10.1145/2980179.2980220,
author = {Nam, Giljoo and Lee, Joo Ho and Wu, Hongzhi and Gutierrez, Diego and Kim, Min H.},
title = {Simultaneous acquisition of microscale reflectance and normals},
year = {2016},
issue_date = {November 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {35},
number = {6},
issn = {0730-0301},
url = {https://doi.org/10.1145/2980179.2980220},
doi = {10.1145/2980179.2980220},
abstract = {Acquiring microscale reflectance and normals is useful for digital documentation and identification of real-world materials. However, its simultaneous acquisition has rarely been explored due to the difficulties of combining both sources of information at such small scale. In this paper, we capture both spatially-varying material appearance (diffuse, specular and roughness) and normals simultaneously at the microscale resolution. We design and build a microscopic light dome with 374 LED lights over the hemisphere, specifically tailored to the characteristics of microscopic imaging. This allows us to achieve the highest resolution for such combined information among current state-of-the-art acquisition systems. We thoroughly test and characterize our system, and provide microscopic appearance measurements of a wide range of common materials, as well as renderings of novel views to validate the applicability of our captured data. Additional applications such as bi-scale material editing from real-world samples are also demonstrated.},
journal = {ACM Trans. Graph.},
month = {dec},
articleno = {185},
numpages = {11},
keywords = {SVBRDF, material appearance, microscopic imaging, photometric stereo}
}

@article{10.14778/2856318.2856327,
author = {Epasto, Alessandro and Lattanzi, Silvio and Mirrokni, Vahab and Sebe, Ismail Oner and Taei, Ahmed and Verma, Sunita},
title = {Ego-net community mining applied to friend suggestion},
year = {2015},
issue_date = {December 2015},
publisher = {VLDB Endowment},
volume = {9},
number = {4},
issn = {2150-8097},
url = {https://doi.org/10.14778/2856318.2856327},
doi = {10.14778/2856318.2856327},
abstract = {In this paper, we present a study of the community structure of ego-networks---the graphs representing the connections among the neighbors of a node---for several online social networks. Toward this goal, we design a new technique to efficiently build and cluster all the ego-nets of a graph in parallel (note that even just building the ego-nets efficiently is challenging on large networks). Our experimental findings are quite compelling: at a microscopic level it is easy to detect high quality communities.Leveraging on this fact we, then, develop new features for friend suggestion based on co-occurrences of two nodes in different ego-nets' communities. Our new features can be computed efficiently on very large scale graphs by just analyzing the neighborhood of each node. Furthermore, we prove formally on a stylized model, and by experimental analysis that this new similarity measure outperforms the classic local features employed for friend suggestions.},
journal = {Proc. VLDB Endow.},
month = {dec},
pages = {324–335},
numpages = {12}
}

@article{10.1145/2611527,
author = {Chu, Xiaowen and Chen, Xiaowei and Jia, Adele Lu and Pouwelse, Johan A. and Epema, Dick H. J.},
title = {Dissecting Darknets: Measurement and Performance Analysis},
year = {2014},
issue_date = {May 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {3},
issn = {1533-5399},
url = {https://doi.org/10.1145/2611527},
doi = {10.1145/2611527},
abstract = {BitTorrent (BT) plays an important role in Internet content distribution. Because public BTs suffer from the free-rider problem, Darknets are becoming increasingly popular, which use Sharing Ratio Enforcement to increase their efficiency. We crawled and traced 17 Darknets from September 2009 to February 2011, and obtained datasets about over 5 million torrents. We conducted a broad range of measurements, including traffic, sites, torrents, and users activities. We found that some of the features of Darknets are noticeably different from public BTs. The results of our study reflect both macroscopic and microscopic aspects of the overall ecosystem of BitTorrent Darknets.},
journal = {ACM Trans. Internet Technol.},
month = {may},
articleno = {7},
numpages = {25},
keywords = {BitTorrent, Darknets, Private tracker, analysis, peer-to-peer networks}
}

@article{10.1109/TCBB.2013.121,
author = {Al Nasr, Kamal and Liu, Chunmei and Rwebangira, Mugizi and Burge, Legand and He, Jing},
title = {Intensity-Based Skeletonization of CryoEM Gray-Scale Images Using a True Segmentation-Free Algorithm},
year = {2013},
issue_date = {September 2013},
publisher = {IEEE Computer Society Press},
address = {Washington, DC, USA},
volume = {10},
number = {5},
issn = {1545-5963},
url = {https://doi.org/10.1109/TCBB.2013.121},
doi = {10.1109/TCBB.2013.121},
abstract = {Cryo-electron microscopy is an experimental technique that is able to produce 3D gray-scale images of protein molecules. In contrast to other experimental techniques, cryo-electron microscopy is capable of visualizing large molecular complexes such as viruses and ribosomes. At medium resolution, the positions of the atoms are not visible and the process cannot proceed. The medium-resolution images produced by cryo-electron microscopy are used to derive the atomic structure of the proteins in de novo modeling. The skeletons of the 3D gray-scale images are used to interpret important information that is helpful in de novo modeling. Unfortunately, not all features of the image can be captured using a single segmentation. In this paper, we present a segmentation-free approach to extract the gray-scale curve-like skeletons. The approach relies on a novel representation of the 3D image, where the image is modeled as a graph and a set of volume trees. A test containing 36 synthesized maps and one authentic map shows that our approach can improve the performance of the two tested tools used in de novo modeling. The improvements were 62 and 13 percent for Gorgon and DP-TOSS, respectively.},
journal = {IEEE/ACM Trans. Comput. Biol. Bioinformatics},
month = {sep},
pages = {1289–1298},
numpages = {10},
keywords = {Image processing, graphs, modeling techniques, volumetric image representation}
}

@article{10.1145/1899396.1899402,
author = {Nzouonta, Josiane and Nakayama, Marvin K. and Borcea, Cristian},
title = {On deriving and incorporating multihop path duration estimates in VANET protocols},
year = {2011},
issue_date = {February 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {21},
number = {2},
issn = {1049-3301},
url = {https://doi.org/10.1145/1899396.1899402},
doi = {10.1145/1899396.1899402},
abstract = {The expected duration of multihop paths can be incorporated at different layers in the protocol stack to improve the performance of mobile ad hoc networks. This article presents two discrete-time and discrete-space Markov chain-based methods, DTMC-CA and DTMC-MFT, to estimate the duration of multihop road-based paths in vehicular ad hoc networks (VANET). The duration of such paths does not depend on individual nodes because packets can be forwarded by any vehicle located along the roads forming the path. DTMC-CA derives probabilistic measures based only on vehicle density for a traffic mobility model, which in this article is the microscopic Cellular Automaton (CA) freeway traffic model. DTMC-MFT generalizes the approach used by DTMC-CA to any vehicular mobility model by focusing on the macroscopic information of vehicles rather than their microscopic characteristics. The proposed analytical models produce performance-measure values comparable to simulation estimates from the validated CA traffic model. Furthermore, this article demonstrates the benefits of incorporating expected path durations into a VANET routing protocol. Simulation results show that the network overhead associated with route maintenance can be reduced to less than half by using the expected path durations.},
journal = {ACM Trans. Model. Comput. Simul.},
month = {feb},
articleno = {14},
numpages = {23},
keywords = {Multihop path duration, road-based routing, vehicular ad hoc networks}
}

@article{10.1109/TCBB.2008.30,
author = {Diaz, Ester and Ayala, Guillermo and Diaz-Fernandez, Maria and Gong, Liang and Toomre, Derek},
title = {Automatic Detection of Large Dense-Core Vesicles in Secretory Cells and Statistical Analysis of Their Intracellular Distribution},
year = {2010},
issue_date = {January 2010},
publisher = {IEEE Computer Society Press},
address = {Washington, DC, USA},
volume = {7},
number = {1},
issn = {1545-5963},
url = {https://doi.org/10.1109/TCBB.2008.30},
doi = {10.1109/TCBB.2008.30},
abstract = {Analyzing the morphological appearance and the spatial distribution of large dense-core vesicles (granules) in the cell cytoplasm is central to the understanding of regulated exocytosis. This paper is concerned with the automatic detection of granules and the statistical analysis of their spatial locations in different cell groups. We model the locations of granules of a given cell as a realization of a finite spatial point process and the point patterns associated with the cell groups as replicated point patterns of different spatial point processes. First, an algorithm to segment the granules using electron microscopy images is proposed. Second, the relative locations of the granules with respect to the plasma membrane are characterized by two functional descriptors: the empirical cumulative distribution function of the distances from the granules to the plasma membrane and the density of granules within a given distance to the plasma membrane. The descriptors of the different cells for each group are compared using bootstrap procedures. Our results show that these descriptors and the testing procedure allow discriminating between control and treated cells. The application of these novel tools to studies of secretion should help in the analysis of diseases associated with dysfunctional secretion, such as diabetes.},
journal = {IEEE/ACM Trans. Comput. Biol. Bioinformatics},
month = {jan},
pages = {2–11},
numpages = {10},
keywords = {Replicated spatial point patterns, bootstrap methods, electron microscopy, exocytosis, image segmentation, large dense-core vesicles.}
}

@article{10.1145/1499096.1499099,
author = {Yang, Chao and Meza, Juan C. and Lee, Byounghak and Wang, Lin-Wang},
title = {KSSOLV—a MATLAB toolbox for solving the Kohn-Sham equations},
year = {2009},
issue_date = {March 2009},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {36},
number = {2},
issn = {0098-3500},
url = {https://doi.org/10.1145/1499096.1499099},
doi = {10.1145/1499096.1499099},
abstract = {We describe the design and implementation of KSSOLV, a MATLAB toolbox for solving a class of nonlinear eigenvalue problems known as the Kohn-Sham equations. These types of problems arise in electronic structure calculations, which are nowadays essential for studying the microscopic quantum mechanical properties of molecules, solids, and other nanoscale materials. KSSOLV is well suited for developing new algorithms for solving the Kohn-Sham equations and is designed to enable researchers in computational and applied mathematics to investigate the convergence properties of the existing algorithms. The toolbox makes use of the object-oriented programming features available in MATLAB so that the process of setting up a physical system is straightforward and the amount of coding effort required to prototype, test, and compare new algorithms is significantly reduced. All of these features should also make this package attractive to other computational scientists and students who wish to study small- to medium-size systems.},
journal = {ACM Trans. Math. Softw.},
month = {apr},
articleno = {10},
numpages = {35},
keywords = {Kohn-Sham equations, Planewave discretization, density functional theory (DFT), direct constrained minimization (DCM), electronic structure calculation, nonlinear eigenvalue problem, pseudopotential, self-consistent field iteration (SCF)}
}

@article{10.1162/evco.2006.14.4.411,
author = {Poli, Riccardo and Stephens, Christopher R.},
title = {Understanding the biases of generalised recombination: part I},
year = {2006},
issue_date = {December 2006},
publisher = {MIT Press},
address = {Cambridge, MA, USA},
volume = {14},
number = {4},
issn = {1063-6560},
url = {https://doi.org/10.1162/evco.2006.14.4.411},
doi = {10.1162/evco.2006.14.4.411},
abstract = {This is the first part of a two-part paper where we propose, model theoretically and study a general notion of recombination for fixed-length strings, where homologous recombination, inversion, gene duplication, gene deletion, diploidy and more are just special cases. The analysis of the model reveals that the notion of schema emerges naturally from the model's equations. In Part I, after describing and characterising the notion of generalised recombination, we derive both microscopic and coarse-grained evolution equations for strings and schemata and illustrate their features with simple examples. Also, we explain the hierarchical nature of the schema evolution equations and show how the theory presented here generalises past work in evolutionary computation. In Part II, the study provides a variety of fixed points for evolution in the case where recombination is used alone, which generalise Geiringer's theorem, in addition, we numerically integrate the infinite-population schema equations for some interesting problems, where selection and recombination are used together to illustrate how these operators interact. Finally, to assess by how much genetic drift can make a system deviate from the infinite-population-model predictions we discuss the results of real GA runs for the same model problems with generalised recombination, selection and finite populations of different sizes.},
journal = {Evol. Comput.},
month = {dec},
pages = {411–432},
numpages = {22}
}

